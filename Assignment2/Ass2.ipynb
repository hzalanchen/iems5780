{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4102e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Student ID: \n",
    "Author: \n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3113a",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2264fc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2531 2537 633 634\n",
      "Real-to-fake new ratio in training sets: 0.9976350019708317\n",
      "Real-to-fake new ratio in testing sets: 0.998422712933754\n",
      "Thus the ratio of real-to-fake news roughly the same in both training and testing sets\n"
     ]
    }
   ],
   "source": [
    "def data_preprocessing():\n",
    "    # read the news.csv file \n",
    "    df = pd.read_csv(\"news.csv\", sep=\",\")\n",
    "    df.columns = [\"id\", \"title\", \"text\", \"label\"]\n",
    "    # Label \"REAL\": 1 \"FAKE\": 0\n",
    "    df.loc[:, \"label\"] = df[\"label\"].apply(lambda x: 1 if x == \"REAL\" else 0)\n",
    "    \n",
    "    # Split the dataset to 80% training set and 20% testing set.\n",
    "    X = df['title'] + \". \" + df[\"text\"]\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, stratify = y, random_state=100)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "\n",
    "def check_ratio(y_train, y_test):\n",
    "    # The ratio of real-to-fake news are roughly the same in both training and testing sets\n",
    "    train_real, train_fake, test_real, test_fake = 0, 0, 0, 0\n",
    "    for i in y_train:\n",
    "        if i == 1: train_fake += 1\n",
    "        else: train_real +=1\n",
    "    for j in y_test:\n",
    "        if j == 1: test_fake += 1\n",
    "        else: test_real += 1\n",
    "    print(train_real, train_fake, test_real, test_fake)\n",
    "    print(\"Real-to-fake new ratio in training sets:\", train_real/train_fake)\n",
    "    print(\"Real-to-fake new ratio in testing sets:\", test_real/test_fake)\n",
    "    print(\"Thus the ratio of real-to-fake news roughly the same in both training and testing sets\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_preprocessing()\n",
    "check_ratio(y_train, y_test)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdce02b",
   "metadata": {},
   "source": [
    "# Training Logistic Regression Models with Adding Bi-Grams to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356cd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LR_with_CountVectorizer(X_train, y_train):\n",
    "    # Prepare pipeline building up using sklearn's CounterVectorizer\n",
    "    pipe_count = Pipeline([\n",
    "        # Add bigram in CounterVectorizer\n",
    "        ('vec', CountVectorizer(ngram_range=(2,2))),\n",
    "        ('log', LogisticRegression())\n",
    "    ])\n",
    "    pipe_count.fit(X_train, y_train)\n",
    "    \n",
    "    return pipe_count\n",
    "\n",
    "def LR_with_TfidfVectorizer(X_train, y_train):\n",
    "    # Prepare pipeline building up using sklearn's TfidfVectorizer\n",
    "    pipe_tfidf = Pipeline([\n",
    "        # Add bigram in TfidfVectorizer\n",
    "        ('vec', TfidfVectorizer(ngram_range=(2,2))), #(1,2)\n",
    "        ('log', LogisticRegression())\n",
    "    ])\n",
    "    pipe_tfidf.fit(X_train, y_train)\n",
    "    \n",
    "    return pipe_tfidf\n",
    "\n",
    "def evalution(pipe_count_model, pipe_tfidf_model, X_test, y_test):\n",
    "    # Compute (i) accuracy, (ii) precision and (iii) recall based on the testing set.\n",
    "    # Evaluate the model1 \n",
    "    print(\" Evalluate model: Logistic Regression Models with Adding Bi-Grams using CounterVectorizer\")\n",
    "    # pipe_count_model = LR_with_CountVectorizer(X_train, y_train)\n",
    "    y_pred_count = pipe_count_model.predict(X_test)\n",
    "    print(\"The following metrics of model1: \")\n",
    "    print(\"Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred_count)))\n",
    "    print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred_count)))\n",
    "    print(\"Accuracy: {:.4f}\".format(recall_score(y_test, y_pred_count)))\n",
    "    \n",
    "    \n",
    "    # Evaluate the model2\n",
    "    print(\" Evalluate model: Logistic Regression Models with Adding Bi-Grams using TfidfVectorizer\")\n",
    "    # pipe_tfidf_model = LR_with_TfidfVectorizer(X_train, y_train)\n",
    "    y_pred_tfidf = pipe_tfidf_model.predict(X_test)\n",
    "    print(\"The following metrics of model2: \")\n",
    "    print(\"Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred_tfidf)))\n",
    "    print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred_tfidf)))\n",
    "    print(\"Accuracy: {:.4f}\".format(recall_score(y_test, y_pred_tfidf)))\n",
    "\n",
    "\n",
    "def save_model(pipe_count_model, pipe_tfidf_model):\n",
    "    # Save the models in a .pkl file using joblib\n",
    "    joblib.dump(pipe_count_model, 'count_model.pkl')\n",
    "    joblib.dump(pipe_tfidf_model, 'tfidf_model.pkl')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5555bbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Evalluate model: Logistic Regression Models with Adding Bi-Grams using CounterVectorizer\n",
      "The following metrics of model1: \n",
      "Accuracy: 0.9132\n",
      "Precision: 0.9396\n",
      "Accuracy: 0.8833\n",
      " Evalluate model: Logistic Regression Models with Adding Bi-Grams using TfidfVectorizer\n",
      "The following metrics of model2: \n",
      "Accuracy: 0.9155\n",
      "Precision: 0.9355\n",
      "Accuracy: 0.8927\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Train the model\n",
    "    model1 = LR_with_CountVectorizer(X_train, y_train)\n",
    "    model2 = LR_with_TfidfVectorizer(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evalution(model1, model2, X_test, y_test)\n",
    "    \n",
    "    #Save the model\n",
    "    save_model(model1, model2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130bf55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
